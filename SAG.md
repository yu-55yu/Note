# Sparse ActionGen (SAG): 基于实时自适应剪枝的扩散策略加速

## 1. 论文核心概念

这篇论文的核心思想是解决“扩散策略 (Diffusion Policy)”在机器人控制中应用时速度过慢的问题。扩散策略虽然能很好地模拟复杂、多模态的动作（即一个任务有多种正确做法），但它需要多步降噪计算，导致延迟很高，无法满足机器人实时控制的需求。过去的加速方法通常使用“静态缓存策略”，即预先设定好哪些计算步骤可以被跳过（剪枝）和重用。但这篇论文发现，机器人在与环境交互的不同阶段（称为 "Rollout Iteration"），其计算的冗余度是动态变化的。一个在任务早期阶段好用的静态策略，到后期可能效果很差。为此，论文提出了 Sparse ActionGen (SAG)，一个“自适应”的加速方法。SAG 的核心创新点在于它训练了一个轻量级的“实时扩散剪枝器” (Real-time Diffusion Pruner)。这个剪枝器会实时“观察”机器人当前所处的环境状态，并 _预测_ 出在接下来的扩散生成过程中，哪些计算单元是冗余的。然后，系统会“剪掉”这些冗余计算，并用一个高效的“全局一对多重用策略” (One-for-All Reusing Strategy) 来填充它们，从而在不牺牲（甚至提升）任务成功率的前提下，实现高达 4 倍的加速。

## 2. 论文内名词解释

1.  **Diffusion Policy (扩散策略)**这是一种用于机器人控制的策略模型。它的特点是能够很好地模拟“多模态动作分布”，即一个任务有多种可能的正确完成方式。其工作原理是通过一个多步骤的“反向降噪”过程，从随机噪声 $a_t^K$ 开始，逐步“去噪”以生成最终的控制动作 $a_t^0$。

2.  **Visuomotor Control (视觉-运动控制)**指机器人根据视觉输入（Visuo-）来控制其运动（-motor）。这是机器人与环境交互的基础，但它对延迟非常敏感，需要“实时”响应（例如，要求 50-1000 Hz 的控制频率），而扩散策略的计算量使其难以满足这一要求。

3.  **Rollout Iteration (展开迭代)**在机器人学中，“Rollout” 指的是机器人执行一次完整任务的过程。“Rollout Iteration” 则是这个过程中的一个单独步骤。在迭代 $t$ 中，机器人接收当前的环境观测 $O_t$，生成一个动作 $a_t$，并执行它，然后环境转移到下一个状态 $O_{t+1}$。这篇论文的关键发现是，在不同的迭代 $t$ 中，最佳的计算剪枝策略是不同的。

4.  **Caching Schedule (缓存策略)**这是一个计划或规则，用于决定在计算过程中，哪些中间结果（称为 Activations）可以被“缓存”（存储起来），并在后续步骤中“重用”（跳过计算，直接使用缓存值），哪些必须被重新计算。过去的策略大多是“静态的”，即这个计划是预先定义好且固定不变的。

5.  **Prune-then-Reuse (先剪枝后重用)**这是 SAG 方法的核心机制。它分为两步（如图 4c 所示）：

- **Prune (剪枝):** 在每一次 Rollout 迭代开始时，根据当前观测 $O_t$，实时的剪枝器会 _预测_ 并决定在即将到来的多步扩散计算中，哪些计算（例如某些 Transformer 模块）是冗余的。
- **Reuse (重用):** 在实际执行扩散计算时，系统会跳过所有被标记为“冗余”的计算，并使用“One-for-All”策略从缓存中提取一个值来替代它们。

6.  **DiT (Diffusion Transformer)**扩散トランスフォーマー。这是论文中扩散策略 $f_{\theta}$ 所使用的具体神经网络架构。它是一个基于 Transformer 的模型，由 $L$ 个堆叠的层组成，每一层又包含三个关键计算块：自注意力 (SA)、交叉注意力 (CA) 和前馈网络 (FFN)。SAG 的剪枝就是针对这 $3L$ 个块在 $K$ 个降噪时间步上进行的。

## 3. 论文方法 

### 3.1 过去方法的问题

1.**扩散策略本身太慢**：扩散策略因为需要多步（例如 50 步）迭代降噪，计算负担巨大。论文举例，在 RTX 4090 上，50 步降噪需要 50 毫秒，这导致控制频率只有 20 Hz，远低于 Franka 机器人臂所需的 50-1000 Hz。 2.**静态缓存策略的局限性**：现有的加速方法（如 EfficientVLA, BAC）依赖于“静态缓存策略”。这些策略是“离线预定义”的，在整个任务执行过程中保持不变。 3.**Motivation (核心动机)**：作者通过实验（图 1）证明了静态策略的缺陷。他们在一个“推方块”任务上 发现：

- 同一个静态策略在任务的不同迭代阶段（Rollout Iteration）表现不一致。
- 不同迭代阶段的“最优”缓存策略是截然不同的。
- 这强烈表明，我们需要一个能够根据环境动态调整的“自适应”策略（Rollout-adaptive）。

### 3.2 整体框架

SAG 的核心是一个与机器人-环境交互相耦合的“先剪枝后重用”管线。它主要由两大模块构成：一个“实时扩散剪枝器” (Real-time Diffusion Pruner) 和一个“一对多重用策略” (One-for-All Reusing Strategy)。
**整体流程 (Prune-then-Reuse Pipeline)**

这是一个两阶段过程，在 _每个_ Rollout 迭代 $t$ 中都会执行：**阶段 1：剪枝 (在扩散计算开始前)**

1.机器人从环境中获取当前观测 $O_t$。 2.将 $O_t$ 输入到“实时扩散剪枝器” $G_{\psi}$ 中。 3.剪枝器 $G_{\psi}$ 会 _一次性_ 预测并生成一个全局的二元剪枝掩码 $\mathcal{M}$。 4.这个掩码 $\mathcal{M}$ 的维度是 $K \times 3L$，其中 $K$ 是总降噪步数，$3L$ 是 DiT 模型中所有可剪枝的块（$L$ 层，每层有 SA, CA, FFN 三个块）。 5.如果 $\mathcal{M}_{k,b} = 1$，表示在第 $k$ 个降噪时间步的第 $b$ 个块的计算是冗余的，应该被“剪枝”。**阶段 2：重用 (在扩散计算过程中)**

1.系统开始执行 $K$ 步降噪过程（从 $k=K$ 到 $1$），以生成动作 $a_t$。 2. 在每一步 $k$ 的每一个块 $b$：

- 系统查询掩码 $\mathcal{M}_{k,b}$。
- **如果 $\mathcal{M}_{k,b} = 1$ (剪枝):**
- 跳过这个块的实际计算 $d_k^b$。
- 使用“One-for-All”策略，从共享缓存 $\tau$ 中读取一个值来替代计算结果。
- 共享缓存 $\tau$ 的值 _保持不变_。
- **如果 $\mathcal{M}_{k,b} = 0$ (计算):**
- 正常执行这个块的计算 $d_k^b$。
- 将新计算出的结果 $d_k^b$ _更新_ 到共享缓存 $\tau$ 中。

---**模块 1：实时扩散剪枝器 $G_{\psi}$ 的架构** (见图 2 右侧)

-**目标**：高效地根据 $O_t$ 预测出全局掩码 $\mathcal{M}$。

- **输入**： 1.当前观测 $O_t$。 2.所有 $K \times 3L$ 个计算单元的“时空坐标”（即时间步索引 $k$ 和块索引 $b$）。
- **架构流程**： 1.**观测编码**: $O_t$ 通过一个视觉编码器 $Enc_{obs}$ 得到观测嵌入 $Enc_{obs}(o_t)$。 2.**时空编码**: 将时间步索引 (Timestep Group) 和块索引 (Block Group) 分别通过“正弦位置编码” (Sinusoidal positional embeddings) 进行编码。然后将这两个编码 _拼接_ (Concatenation)，而不是相加，以保留各自的信息。 3.将拼接后的时空坐标表示送入一个 Transformer 编码器，得到时空特征 $z$。 4.**特征融合**: 将观测嵌入和时空特征 $z$ 再次拼接：$h = \text{Concat}(Enc_{obs}(o_t), z)$。 5.**掩码预测**: 将融合后的特征 $h$ 送入一个 3 层 MLP，生成 $K \times 3L \times 2$ 维度的 logits $I$。 6.最后通过 `argmax` 操作得到二元掩码 $\mathcal{M}$。 -**训练 (Optimization Objective)** -为了让不可导的 `argmax` 能够反向传播梯度，论文使用了 Gumbel-Softmax 或 Straight-Through Estimator (STE)。 -总的损失函数 $\mathcal{L}_{total}$包含两部分： 1.**保真度损失 $\mathcal{L}_{fidelity}$**: 确保剪枝后的策略 $\pi'$ 仍然能产生和专家（Ground Truth）一致的动作。这是通过在一个参考数据集 $D_{ref}$（约 5% 的原始数据）上计算剪枝后动作与真实动作 $a^*$ 之间的距离（如 L1 或 L2 距离）来实现的。
  $$
      \mathcal{L}_{fidelity} = \mathbb{E}_{(o,a^{*})\sim\mathcal{D}_{eef}}[||\pi^{\prime}(o,\mathcal{M})-a^{*}||]
      $$ 2.**稀疏度损失 $\mathcal{L}_{sparsity}$**: 这是一个全局稀疏度约束，用于确保剪枝器 _整体上_ 达到了一个预设的目标剪枝率 $\rho$（例如 $\rho=0.91$）。它使用平均绝对误差 (MAE) 来惩罚实际剪枝率与目标 $\rho$ 之间的偏差。
  $$
      \mathcal{L}_{sparsity} = ||\frac{1}{N}\sum_{k=1}^{K}\sum_{b=1}^{B}\mathcal{M}_{k,b}-\rho||
      $$ -**总损失**: $\mathcal{L}_{total} = \mathcal{L}_{fidelity} + \mathcal{L}_{sparsity}$(论文中设置 $\beta=1$)。

---

**模块 2：一对多重用策略 (One-for-All Reusing Strategy)**

-**动机**：作者发现（图 4a），计算冗余不仅存在于时间步之间（Cross-timestep），也存在于 _不同块之间_ (Cross-block)。而以前的策略（图 4b 左）是“块隔离”的，即每个块 $b$ 都有一个独立的缓存，这忽视了跨块的冗余。 -**SAG 的策略** (图 4b 右)： -不为每个块单独维护缓存，而是为 _所有同类型的块_（例如所有的 SA 块）维护一个 _共享的缓存缓冲区_ $\tau$。 -这允许“跨块重用”，例如在 $k$ 步计算出的 $b$ 块的激活值，可以被 $k+1$ 步的 $b+1$ 块重用。论文称之为“zig-zag” (Z 字形) 重用。

- **计算公式**： -**隐藏状态更新**：
  $$
  h_{k}^{\lfloor b/3\rfloor} = h_{k}^{\lfloor b/3\rfloor-1} + (1-\mathcal{M}_{k}^{b}) \cdot d_{k}^{b} + \mathcal{M}_{k}^{b} \cdot \tau
  $$
- $h$ 是隐藏状态， $d_k^b$ 是第 $k$ 步第 $b$ 块的计算输出。
- 如果 $\mathcal{M}_k^b=1$ (剪枝)，第二项为 0，添加缓存 $\tau$。
- 如果 $\mathcal{M}_k^b=0$ (计算)，第三项为 0，添加新计算的 $d_k^b$。 -**缓存更新**：
  $$
  \tau = (1-\mathcal{M}_{k}^{b}) \cdot d_{k}^{b} + \mathcal{M}_{k}^{b} \cdot \tau
  $$
- 如果 $\mathcal{M}_k^b=1$ (剪枝)，$\tau = \tau$ (缓存不变)。
- 如果 $\mathcal{M}_k^b=0$ (计算)，$\tau = d_k^b$ (缓存更新为新值)。

### 3.3 核心难点解析

1.  **如何在不增加延迟的情况下实现“自适应”？**

- **难点**: “自适应”听起来就需要实时分析。如果像传统方法那样，先完整计算一次，分析激活值的相似度，然后再决定 _下一次_ 迭代怎么缓存，这个“分析”本身就带来了巨大的延迟，得不偿失。
- **SAG 的妙解 (预测)**: SAG 不在“事后分析”，而在“事前预测” (a priori)。它训练的剪枝器 $G_{\psi}$学习到了“环境观测 $O_t$” 和“计算冗余模式”之间的相关性。这个剪枝器本身被设计得极其高效（参数少、推理快），它只需要一次前向传播，就能生成 _所有 K 步_ 的完整剪枝计划 $\mathcal{M}$。这个额外的开销非常小（<0.3% 的总 FLOPs），因此可以被认为是“实时”的。

2.  **如何高效地训练剪枝器？**

- **难点**: 剪枝器 $G_{\psi}$ 的学习目标很矛盾：(1) 剪枝后的策略要保持高成功率；(2) 剪枝器必须严格遵守极高（如 91%）的剪枝率。
- **SAG 的妙解 (全局损失)**: SAG 使用了 $\mathcal{L}_{fidelity}$ (保真度损失) 来确保 (1)，使用 $\mathcal{L}_{sparsity}$ (稀疏度损失) 来确保 (2)。
- 关键在于 $\mathcal{L}_{sparsity}$ 是一个“全局稀疏度损失”。它不要求 _每个_ 块都必须剪枝 91%，而是要求 _所有块的平均_ 剪枝率达到 91%。这给了剪枝器极大的灵活性：它可以在“关键”的计算块（例如任务快完成时的最后几步）上分配更多的计算资源（剪枝率低），而在“不重要”的计算块（例如任务刚开始时）上分配极少的资源（剪枝率高）。这远比“一刀切”的均匀剪枝要智能得多。

3.  **如何最大化缓存的利用率？**

- **难点**: 传统的缓存策略是“块隔离”的 (Block-wise)。第 1 层的 SA 块的缓存，只会被第 1 层的 SA 块在未来的时间步中使用。但论文分析发现，第 1 层的 SA 块和第 2 层的 SA 块的计算结果可能也非常相似（即跨块冗余）。
- **SAG 的妙解 (One-for-All)**: SAG 打破了这种隔离。它为所有 SA 块设置一个 _共享缓存_ $\tau$。这意味着，第 1 层 SA 块在 $k=10$ 步的计算结果，可以被第 2 层 SA 块在 $k=11$ 步重用，也可以被第 3 层 SA 块在 $k=12$ 步重用。这种“Z 字形”的重用方式（见图 4b 右）从全局角度最大化了冗余计算的消除。

## 4. 实验结果与分析 

### 4.1 实验设置

1.  **模型**:

- 使用基于 Transformer 的扩散策略 (DP-T)。
- 使用的是 Diffusion Policy 官方发布的预训练模型权重。

2.  **数据集 (Benchmarks)**:

- **RoboMimic**: 包含 5 个机器人操作任务 (Lift, Can, Square, Transport, Tool hang)。
- **数据类型**: 分为“熟练人类” (Proficient Human, PH) 演示数据和“混合人类” (Mixed Human, MH) 演示数据。
- **Franka Kitchen**: 一个更复杂的多阶段厨房环境操作任务。

3.  **评估指标**:

- 任务成功率 (Success Rate, %)。
- 加速比 (Speedup, ↑)。 4.**对比方法 (Baselines)**:
- **Full Precision**: 原始的、未加速的 DP-T 模型。
- **EfficientVLA**: 一种使用均匀（固定间隔）缓存策略的加速方法。
- **L2C**: 一种从图像生成领域改编过来的、基于学习的缓存方法。
- **BAC**: 一种块自适应的缓存方法。

5.  **超参数设置**:

- **硬件**: NVIDIA Tesla V100S 32G GPU。
- **目标剪枝率 $\rho$**: 论文中凭经验设为 91%。
- **剪枝器训练**: 训练 30 个 epochs，batch size 为 32，学习率 $1e^{-4}$。
- **参考数据集 $D_{ref}$**: 从原始训练数据中均匀采样约 5% 构成。

### 4.2 实验结果

1.**总体效果 (Tables 1, 2, 3)**: SAG 在所有基准测试上都实现了性能和效率的最佳权衡。 2. **性能与加速**:

- SAG 在 PH 数据集上平均成功率达到 85%（高于基准的 83%），平均加速 3.63x。
- SAG 在 MH 数据集上平均成功率达到 86%（高于基准的 81%），平均加速 3.77x。
- **惊人的结果**: SAG 不仅没有牺牲性能，反而 _提升了_ 任务成功率。
- 在最复杂的多阶段 Kitchen 任务上，SAG 达到了 100% 的成功率（无损），同时获得了 4.03x 的最高加速。

3.  **与基线对比**:

- 所有其他加速方法在实现同等加速比时，都无法保持无损性能。
- **EfficientVLA** 的固定策略在复杂任务上（如 Kitchen）完全失败，成功率降至 3%。
- **L2C** 的策略过于僵化，只能提供约 1.28x 的有限加速。
- **BAC** 无法适应动态的 Rollout 过程，在 Transport 等复杂任务上表现不佳。 4.**消融实验 (Ablation Study - Table 4)**:
- **去掉“实时剪枝器”** (即使用一个固定的剪枝策略): 性能显著下降。这证明了“环境感知”和“实时自适应”是实现无损加速的关键。
- **去掉“One-for-All 重用”** (即使用传统的块隔离缓存): 性能平均下降了 12%。这证明了“跨块重用”策略的高效性。
- **去掉“全局稀疏度损失”** (即使用均匀的块稀疏度损失): 导致了“灾难性的崩溃”。多个任务上的成功率直接降到了 0%。这证明了允许剪枝器“非均匀”地分配计算资源是“至关重要”的。

1.  **定性结果 (Qualitative Results - Figure 5)**:

- 可视化剪枝器预测的稀疏模式（图 5 下方），可以看到大片的白色区域，表明计算确实是高度稀疏的。
- 更重要的是，随着机器人移动（观测 $O_t$ 变化），稀疏模式也在随之 _变化_。这直观地证明了剪枝器确实在根据环境动态进行“自适应”。

## 5. 结论 

### 5.1 论文的贡献根据论文总结，其主要贡献有四点：

1.**提出 SAG**: 介绍了一种名为 Sparse ActionGen (SAG) 的“Rollout-adaptive”（即随任务进程自适应）的加速方法，解决了扩散策略的延迟问题。 2.**设计实时剪枝器**: 提出了一个“实时扩散剪枝器”，它以当前环境观测为条件（实现环境感知），并且自身具有极高的推理效率（实现实时预测）。 3.**全局剪枝与重用**: 从“全局分配”的角度优化了管线，引入了“全局稀疏度损失”（用于智能分配计算资源）和“一对多重用策略”（用于跨块和跨时间步重用激活）。 4.**SOTA 结果**: 实验证明，SAG 能剪枝超过 90% 的计算，在不更新模型参数的情况下，实现高达 4x 的“无损”加速。

