# BAC: 基于块级自适应缓存的扩散策略加速

## 1. 论文核心概念

这篇论文的核心目标是解决 Diffusion Policy（扩散策略）模型在机器人控制应用中的一个关键问题：计算成本太高，导致无法进行实时控制。
论文的核心洞察（insight）在于，Diffusion Policy 在生成动作的多个“去噪”步骤中存在大量的计算冗余，但这种冗余在不同的时间步（timestep）和 Transformer 模型的不同计算块（block）之间是*非均匀*分布的。基于这一观察，论文提出了一种名为 **Block-wise Adaptive Caching (BAC)** 的方法。这是一种无需重新训练的（training-free）插件式技术，它通过为 Transformer 的*每一个块*（如自注意力、前馈网络等）计算一个*自适应*的（非均匀的）缓存更新时间表，来跳过冗余计算。

BAC 方法由两个关键组件构成：

1.  **Adaptive Caching Scheduler (ACS)**：一个自适应缓存调度器，它使用动态规划来智能地找出每个块的最佳缓存更新时刻，以最大化特征相似性（即最小化缓存误差）。
2.  **Bubbling Union Algorithm (BUA)**：一个“冒泡联合算法”，用于解决一个关键的“误差突增”（Error Surge）问题。这个问题发生在天真地应用块级缓存时，下游块（如下游 FFN）的误差会因为上游块的缓存误差传播而被放大。BUA 通过强制相关的上游块在下游 FFN 更新时也进行更新，从而截断这种误差传播。最终，BAC 能够在不降低（甚至有时略微提升）任务成功率的情况下，实现高达 3 倍的推理加速。

## 2. 论文内名词解释

1.  **Diffusion Policy (扩散策略)**：这是一种用于机器人控制的策略模型。它借鉴了扩散模型的思想，通过一个条件去噪过程来学习和建模复杂的动作分布。在机器人 visuomotor（视觉 - 动作）控制任务中，它将控制过程视为从一个条件扩散模型中采样动作。它虽然表现强大，但其迭代去噪的特性导致计算量巨大，难以满足实时控制所需的高频率（例如 30 - 50 Hz）。
2.  **Block - wise Adaptive Caching (BAC)**：即“块级自适应缓存”。这是本文提出的核心加速方法。它是一个无需训练的插件，通过在 Transformer 模型的“块”级别（例如，自注意力块或 FFN 块）上缓存和重用中间特征来实现加速。其关键特性是“块级”（Block - wise），意味着每个块都有自己*独立*的缓存时间表；以及“自适应”（Adaptive），意味着时间表是根据特征相似性动态计算的，而不是固定的时间间隔。
3.  **Adaptive Caching Scheduler (ACS)**：即“自适应缓存调度器”。这是 BAC 的第一个核心组件。它的任务是为*单个*计算块，在给定的计算预算（例如，总共只更新 $M$ 次）下，找到一组*最优*的缓存更新时间步。它通过一个动态规划求解器，来最大化“跳过”的步骤与“缓存”的步骤之间的全局特征相似性。
4.  **Error Surge (误差突增)**：这是论文发现并着力解决的一个关键问题。当直接为每个块应用独立的 ACS 调度时（即 Block - wise ACS），会导致严重的性能崩溃。论文发现，这种崩溃是由于“块间缓存误差传播”引起的：一个*上游*块（例如 SA 块）由于使用了缓存而存在较小的“重用误差”；当一个*下游*块（特别是 FFN 块）在此时进行“更新”时，它会输入这个带有误差的特征，并且由于 FFN 块缺乏归一化等结构，会*放大*这个上游误差，导致“更新诱导的误差”急剧增加，即“误差突增”。
5.  **Bubbling Union Algorithm (BUA)**：即“冒泡联合算法”。这是 BAC 的第二个核心组件，专门用于解决“误差突增”问题。其核心思想是：如果一个下游的 FFN 块计划在 $t$ 时刻更新缓存，那么 BUA 会检查所有向它提供输入的*上游*块。如果某个上游块被认定为“高误差风险”块，BUA 会*强制*这个上游块也在 $t$ 时刻更新缓存（即使 ACS 原本没这么安排）。这通过“联合”（Union）二者的更新时间表，确保了 FFN 在更新时能获得来自上游的最新、最准确的特征，从而“截断”了误差的传播。
6.  **Diffusion Transformer (DiT)**：本文评估的 Diffusion Policy 所使用的具体模型架构。它使用一个基于 Transformer 的解码器来代替传统的 U - Net。这个解码器由 $L$ 层堆叠而成，每层包含三个核心块：一个自注意力（SA）块、一个交叉注意力（CA）块（用于处理时间步和观测条件）和一个前馈网络（FFN）块。BAC 的“块级”缓存就是针对这 L\*(SA+CA+FFN) 个块中的每一个来独立操作的。

## 3. 论文方法

3. 1 过去方法的问题

1. **Diffusion Policy 计算量过大**：Diffusion Policy 在机器人控制上效果很好，但它依赖于迭代去噪过程。例如，在 6 自由度机械臂任务上，执行 50 个去噪步骤可能总共耗时 50 毫秒，这导致动作更新率仅为 10 Hz，远低于平滑实时控制所需的 30 - 50 Hz。
1. **现有加速方法不适用**：已有的缓存加速方法（如 DeepCache）主要是为基于 U - Net 架构的图像和视频生成模型设计的，它们无法直接推广到 Diffusion Policy 所使用的 Transformer 架构（DiT）。
1. **Transformer 缓存方法过于粗糙**：少数为 DiT 设计的缓存方法通常采用“粗粒度”策略，例如，让*所有*块共享一个*统一*的（Uniform）缓存时间表（例如，每 3 步更新一次）。
1. **Motivation (关键观察)**：本文的动机来源于一个关键观察：计算冗余是*非均匀*的。通过分析 DiT 内部的特征相似性（如图 1 所示），作者发现：(1) 特征相似性随时间步非均匀变化；(2) 不同的块（SA, CA, FFN）表现出截然不同的时间相似性模式。因此，使用统一的时间表是次优的，我们需要一个“块级”且“自适应”的缓存策略。

1. 2 整体框架
   BAC 方法是一个包含两个阶段的离线（offline）计算和在线（online）应用的框架。

**缓存范式 (Update - then - reuse)** BAC 遵循“更新 - 然后 - 重用”的范式。对于总共 $K$ 个去噪步骤，我们为每个块计算一个更新步骤集合 $\mathcal{C} \subseteq \{1, . . . , K\}$。

    -   **更新步骤 (k ∈ C)**：在步骤 $k$，正常计算该块的输出 $b_k$，并将其存入缓存。
    -   **重用步骤 (k ∉ C)**：在步骤 $k$，跳过计算，直接重用缓存中存储的特征。（注意：论文中的 $k' = \min\{i \in \mathcal{C} | i > k\}$ 公式在上下文中似乎有误，其 DP 求解器和目标 隐含的逻辑是重用*上一个*更新点的缓存，即 $k' = \max\{i \in \mathcal{C} | i \le k\}$）。BAC 的核心就是如何为每个块智能地计算出这个集合 $\mathcal{C}$。

这分为两步：

**第一部分：Adaptive Caching Scheduler (ACS)**
ACS 的目标是找到一组 $M$ 个更新步骤 $\mathcal{C}^* = \{c_1, . . . , c_M\}$，使得在这些步骤之间（重用缓存的区间）的特征相似性总和最大。

1. **相似性定义**：使用余弦相似度 $s_k$ 来衡量连续步骤 $k$ 和 $k    -  1$ 的特征 $b_k$ 和 $b_{k    -  1}$ 之间的相似性。

$$
s_{k} = \cos(b_{k}, b_{k    -  1}) = \frac{b_{k    -  1}^{\top}b_{k}}{||b_{k    -  1}||_{2}||b_{k}||_{2}}
$$

2. **区间相似性**：定义 $\phi(i, j)$ 为从 $i+1$ 步到 $j$ 步的连续相似性之和。这代表了如果在 $i$ 步更新、在 $j$ 步再次更新，这个区间内的总相似度。

$$
\phi(i, j) = \sum_{k=i+1}^{j} s_{k}
$$

3. **优化目标**：找到大小为 $M$ 的集合 $\mathcal{C}$，最大化总的区间相似性。

$$
\max_{\mathcal{C} \subseteq \{1, . . . , K\}, |\mathcal{C}|=M} \sum_{m=0}^{M} \phi(c_m, c_{m+1}    -  1)
$$其中 $c_0=0, c_{M+1}=K$ 是边界条件。

4. **动态规划 (DP) 求解**：这是一个组合优化问题，穷举搜索不可行。ACS 使用 DP 解决。

    -   **DP 状态**：$DP[m][j]$ 定义为“使用 $m$ 次更新，且第 $m$ 次更新恰好在步骤 $j$ 时”所能达到的最大累积相似度。
    -   **DP 转移方程**：要计算 $DP[m][j]$，我们枚举*上一次*（第 $m    -  1$ 次）更新可能发生的所有位置 $i$（$0 \le i < j$），并选择最优的一个。
$$

DP[m][j] = \max\_{0 \le i < j} \{DP[m - 1][i] + \phi(i, j)\}

$$
  -   **路径回溯**：为了找到具体的更新步骤，使用一个指针矩阵 $PTR$ 记录下导致最大值的那个 $i$。
$$

PTR[m][j] = \arg\max\_{0 \le i < j} \{DP[m - 1][i] + \phi(i, j)\}

$$
  -   **获得最优调度**：首先，DP 表填满后，找到 $M$ 次更新的最佳终点 $j^* = \arg\max_{1 \le j \le K} DP[M][j]$。然后，从 $c_M^* = j^*$ 开始，使用 $PTR$ 矩阵反向回溯， $c_{m    -  1}^* = PTR[m][c_m^*]$，直到找到所有 $M$ 个步骤 $\mathcal{C}^* = \{c_1^*, . . . , c_M^*\}$。

5. **离线计算**：ACS 依赖于任务内的高度“情节同质性”（high episode homogeneity）。这意味着在同一个任务中（例如 $Square_{ph}$），即使场景不同（demo 11001 vs 20000），其特征相似性矩阵也几乎保持一致（如图 7 所示）。因此，这个 DP 过程只需在推理前对每个*任务*运行一次，几乎不增加额外成本。

**第二部分：Bubbling Union Algorithm (BUA)**
BUA 解决了“Block    -  wise ACS”（即对每个块独立使用 ACS）导致的“误差突增”问题。

**核心思想**：如果一个下游 FFN 块要更新，那么它依赖的、且具有高缓存误差风险的*上游*块也*必须*在此时更新。

1.  **阶段 1：选择高误差的上游块 (Select Upstream Blocks)**

    -   目标是识别哪些上游块在“重用”缓存时（reuse    -  induced error）最容易产生大误差。
  -   计算每个块 $j$ 的一个误差分数 $l_j$，即所有时间步 $t$ 和 $u$ 之间特征差异的 $l_1$ 范数的平均值。
$$

l*j = \frac{1}{K^2} \sum*{t=1}^K \sum\_{u=1}^K ||X_j^{(t)} - X_j^{(u)}||\_1

$$
  -   选择 $l_j$ 分数最高的 top    -  $k$ 个块（例如 $k=5$），将它们放入集合 $\mathcal{U}$（代表高风险的上游块）。

2.  **阶段 2：自下而上联合更新时间步 (Unioning Update Timesteps)**
  -   这一步修改在 $\mathcal{U}$ 中块的 ACS 调度。
  -   对于 $\mathcal{U}$ 中的每一个上游块 $u$（例如，`layers. 5. SA`）：
  -  令 $C(u)$ 为 ACS 为它计算的原始更新时间表。
  -  令 $D(u)$ 为所有在 $u$ *下游*的 FFN 块的集合（例如，`layers. 5. FFN`, `layers. 6. FFN`, `layers. 7. FFN`）。
  -  $u$ 的新时间表 $C(u)$，是其*原始*时间表，与它*所有*下游 FFN 块（$v \in D(u)$）的时间表 $C(v)$ 的“并集”（Union）。
$$

C(u) = C(u) \cup \bigcup\_{v \in D(u)} C(v)

$$
-  这个“冒泡联合”操作强制上游块 $u$ 在任何下游 FFN 块 $v$ 更新时也必须更新，从而保证了 $v$ 在更新时总能获取到来自 $u$ 的最新特征，截断了误差传播。

3. 3 核心难点解析

这一部分我们用一个更直白的例子来解释“误差突增”和 BUA 算法。

**难点：为什么“块级自适应缓存 (Block    -  wise ACS)” 会失败？**

想象一条 Transformer 流水线，由 8 层（Layer 0 到 7）组成，每层有 3 个工人（SA, CA, FFN）。

1.   **独立的 ACS 调度**：ACS 就像一个效率顾问，他告诉每个工人（Block）：“你很熟练，你不需要每一步都干活（计算），你可以按照这个时间表（ACS 调度）休息（重用缓存）。”
2.   **问题出现**：假设在 $t=30$ 时刻：
  -   `Layer 5` 的 `SA` 工人（上游块）的调度表说：休息（重用 $t=20$ 的缓存）。
  -   `Layer 5` 的 `FFN` 工人（下游块）的调度表说：工作（更新缓存）。
1.   **误差突增**：
  -  `SA` 工人休息了，他传递给 `FFN` 的是一个 $t=20$ 的旧特征。这个旧特征本身就带有一点“重用误差”（Reuse    -  induced Error）。
  -  `FFN` 工人（一个没有归一化层的工人）拿到了这个带小误差的旧特征，然后开始“工作”（更新计算）。
  -  在 `FFN` 的计算过程中（例如 $W_{out}\phi(W_{in}LN(X) + . . . )$），这个输入的小误差被*急剧放大*了。这被称为“更新诱导的误差”（Update    -  induced Error）。
  -  结果：`FFN` 块在 $t=30$ 时刻的输出（见图 3a）突然产生了一个巨大的误差尖峰，导致整个模型的性能崩溃。

**BUA 如何解决这个问题？**

BUA 就像是流水线上的“安全主管”。

1. **阶段 1 (识别风险)**：BUA 事先（离线）评估了所有工人，发现 `Layer 5 SA` 工人（以及其他 4 个）的活儿最容易出错（Top    -  k $l_j$ score）。他把这 5 个工人标记为高风险集合 $\mathcal{U}$。
2. **阶段 2 (修改规则)**：BUA 颁布新规定（Union）：
  -   “对于所有 FFN 工人（例如 `Layer 5 FFN`）：你们按原计划（ACS 调度）工作。”
  -  “对于所有*高风险*的上游工人（例如 `Layer 5 SA` $\in \mathcal{U}$）：你必须*额外*遵守一条规定：只要你*下游*的任何一个 FFN 工人（`Layer 5 FFN`）在工作（更新），你*也必须*立刻回来工作（更新）！”

3. **解决问题**：
  -   现在，在 $t=30$ 时刻：
  -   `Layer 5 FFN` 按计划工作（更新）。
  -   BUA 规则启动：`Layer 5 SA`（高风险上游块）被*强制*也必须工作（更新），即使他自己的 ACS 调度表说要休息。
  -   `FFN` 工人拿到了 `SA` 工人新鲜出炉的、零误差的特征。
  -  `FFN` 正常更新，没有误差被放大。“误差突增”消失了（如图 3a `Unified` vs `Block    -  wise` 所示，BUA 的目标是消除 `Block    -  wise` 的尖峰）。

## 4.   实验结果与分析

4. 1 实验设置

1. **模型**：使用基于 Transformer 的 Diffusion Policy (DP    -  T)。BAC 是作为其插件模块实现的。
2. **数据集 (Benchmarks)**：在四个机器人操纵基准上进行评估：
  -  **Robomimic**：包含 5 个子任务（Can, Lift, Square, Transport, Tool_Hang）。使用两种演示数据：Proficient    -  Human (PH) 和 Mixed    -  Human (MH)。
  -  **Push    -  T**：一个 T 形块推动任务。
  -  **Multimodal Block Pushing (Block Pushing)**：一个多模态任务，将两个块推入目标区域（脚本生成的数据）。
  -  **Kitchen**：一个多步骤的厨房环境操纵任务。
1.   **指标**：
  -  **效率 (Efficiency)**：FLOPs（浮点运算次数）和 Speedup（加速倍数）。
  -  **精度 (Precision)**：Success Rate（成功率）。对于 Push    -  T，使用目标区域覆盖率。
2.   **对比方法 (Baselines)**：
  -  **Full Precision**：即原始的 DP    -  T 模型，不使用任何缓存，作为性能和速度的基准。
  -  **Uniform**：一种基线缓存方法，其中所有块*同时*、_以固定的时间间隔_（例如 $S=7$ 或 $S=10$）更新其缓存。
5. **超参数**：BUA 中的 $k$（选择 top    -  k 高误差上游块）在所有实验中设置为 5。缓存更新的总步数 $S$（即计算预算）被设置为 7 或 10。

4. 2 实验结果

1. **BAC 实现了无损加速**：在 $S=10$（更新 10 步）的设置下，BAC 实现了“无损”加速。在三个主要基准类别（PH, MH, Multi    -  stage）上，BAC 的平均成功率（0. 79, 0. 77, 0. 98）与“Full Precision”（0. 76, 0. 76, 0. 98）持平，甚至略有提高。
2. **显著的加速效果**：BAC 在大多数任务上实现了超过 3. 4 倍的稳定加速（见表 1）。
3.   **BAC 远优于 Uniform 基线**：
  -  **稳定性**：BAC 在所有任务上都保持了强大和稳定的性能。
  -  **困难任务**：在 $Transport_{mh}$ 和 $Kitchen_{p4}$ 这样的困难任务上，Uniform 基线的方法几乎完全失败（成功率接近 0），而 BAC 则成功地恢复了正确的动作生成，保持了高成功率。
4.   **消融实验 (Ablation Study) 证明了 BUA 的必要性**：
  -  表 2 展示了 BAC 中两个组件（ACS 和 BUA）的有效性。
  -  `Unified ACS` (只用 ACS，且所有块共享一个时间表) 相比 `Uniform` 有所提升 (0. 72 vs 0. 65)，证明了 ACS 的自适应调度优于固定的间隔。
  -  `Block    -  wise ACS` (对每个块用 ACS，但*不用 BUA*) 性能崩溃。其平均成功率降至 0. 65，且在 $Tool_{ph}$ 任务上彻底失败（成功率 0. 03/0. 05）。
  -  **关键结论**：`Block    -  wise ACS` 的失败*证实*了“误差突增”现象的存在。
  -  `Block    -  wise ACS + BUA` (完整的 BAC 方法) 恢复了全部性能，达到 0. 79 的平均成功率。这证明了 BUA 算法*有效*地解决了误差突增问题。

## 5.   结论

5. 1 论文的贡献

1. **提出了 BAC**：一种新颖的、无需训练的（training    -  free）加速方法，专为 Transformer 架构的 Diffusion Policy 设计。
2. **设计了 ACS**：开发了自适应缓存调度器（ACS），它使用动态规划（DP）求解器来优化块级缓存时间表，以最小化“重用误差”。
3. **发现并分析了“误差突增”**：论文首次从理论和经验上深入分析了在 DiT 中应用块级缓存时出现的“误差突增”现象，并将其归因于块间（特别是 FFN 块）的误差传播。
4. **设计了 BUA**：提出了冒泡联合算法（BUA）来精确地“截断”这种误差传播，解决了“更新诱导的误差”。
5. **实现了 SOTA 性能**：实验证明，BAC 实现了超过 3 倍的显著推理加速，同时保持了无损的性能。

5. 2 论文的限制

1. **可能放大基础模型的误差**：论文指出，如果基础（base）Diffusion Policy 模型在某个任务上的原始准确率就非常低，BAC 的缓存策略可能会无意中放大这种不准确性。例如，在 $Transport_{mh}$ 基准测试中观察到了轻微的性能下降。
2. **缺乏真实机器人实验**：由于设备限制，该方法尚未在真实的机器人硬件上进行视觉    -  语言    -  动作（VLA）模型的实验验证。

5. 3 未来的方向

1.  **真实世界部署**：未来的工作计划是在真实的 VLA 任务中解决真实机器人部署的问题。
2.   **（隐含的）鲁棒性**：研究如何在基础模型性能较差时，避免缓存策略放大其固有的不准确性。
$$
